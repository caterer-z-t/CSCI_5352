{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph & Network Libraries\n",
    "import networkx as nx\n",
    "import igraph as ig\n",
    "\n",
    "# Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import deque, defaultdict\n",
    "from itertools import combinations\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from plotnine import *\n",
    "\n",
    "# Statistical & Utility Libraries\n",
    "from scipy.stats import zscore\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. (20 pts) The double-edge swap can also be used to insert a speciﬁc amount of randomness into a network. In this way, we can use it to deﬁne a parametric network model that contains a speciﬁed amount of “real” structure, which we can get from an empirical network. Let $r$ be the number of double-edge swaps we have applied to some input graph $G$.\n",
    "\n",
    "Using the UC Berkeley social network from the FB100 data set, design and carry out a numerical experiment to answer the following question: as a function of $r$, how does the clustering coeﬃcient $C$ and mean path length $\\langle \\ell \\rangle$ relax onto those of the corresponding conﬁguration model? As references, overlay in your plots horizontal lines for the $C$ and $\\langle \\ell \\rangle$ when you have applied $r = 20m$ swaps (which will be the values expected under the conﬁguration model). Comment on how “random” Berkeley’s social network was to begin with, in what ways, and\n",
    "on the rate at which randomization destroys the empirical patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Berkeley social network\n",
    "uc_berkeley_filepath = \"../hw1/facebook100txt/Berkeley13.txt\"\n",
    "\n",
    "\n",
    "def read_graph(filepath):\n",
    "    \"\"\"Reads the UC Berkeley social network from FB100 dataset.\"\"\"\n",
    "    G = nx.read_edgelist(filepath, nodetype=int, comments='id')\n",
    "    return G\n",
    "\n",
    "\n",
    "berkeley_graph = read_graph(uc_berkeley_filepath)\n",
    "\n",
    "# print(\n",
    "#     f\"Nodes: {berkeley_graph.number_of_nodes()}, Edges: {berkeley_graph.number_of_edges()}\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nPlease See the rest of the code in the Python file in \\n\\n`hw/hw2/prob_3.py`\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Please See the rest of the code in the Python file in \n",
    "\n",
    "`hw/hw2/prob_3.py`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. (30 pts) In network data science, the conﬁguration model serves as the key null model for deciding whether some network measure x = f (G) is big or small or typical or unusual. Visit the Index of Complex Networks (ICON) at icon.colorado.edu and obtain your choice of\n",
    "\n",
    "- 1 online / social network\n",
    "- 1 food web / biological network, and\n",
    "- 1 connectome / biological network.\n",
    "\n",
    "Treating them as simple graphs, design and carry out a numerical experiment to answer the following question for each network: to what degree can the network’s (i) clustering coeﬃcient $C$ and (ii) mean path length $\\langle \\ell \\rangle$ be explained by its degree structure? Display your results using plots showing the null distributions of these statistics under the conﬁguration model, and overlay on that distribution a vertical line showing the empirical value for that network. Discuss (i) whether the empirical values are big, small, typical, or unusual, (ii) what that\n",
    "conclusion implies about the structure of these networks, and (iii) what hypotheses it suggests about the underlying data generating process that produced these networks.\n",
    "\n",
    "Hint: A good null distribution requires around 1000 conﬁguration model random graphs.\n",
    "Applying a double-edge swap operation $r = 20m$ times, starting with the empirical graph\n",
    "at $r = 0$, is suﬃcient to generate a single corresponding conﬁguration model random graph. The bigger the graphs you choose, the longer your compute times will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zebra_filepath = \"files/moreno_zebra/out.moreno_zebra_zebra\"\n",
    "food_web_filepath = \"files/fw/out.maayan-foodweb\"\n",
    "connectome_filepath = \"files/con/rhesus_brain_2.graphml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_out_network_data(filepath, type = 'directed'):\n",
    "    \"\"\"\n",
    "    Reads network data from edge list files, handling comment lines.\n",
    "\n",
    "    Parameters:\n",
    "    filepath (str): Path to the network data file\n",
    "\n",
    "    Returns:\n",
    "    networkx.Graph: An undirected NetworkX graph object\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if type == 'directed':\n",
    "            # Create a directed graph\n",
    "            G = nx.DiGraph()\n",
    "        else:\n",
    "        # Create an undirected graph\n",
    "            G = nx.Graph()\n",
    "\n",
    "        # Read edges, skipping comment lines\n",
    "        with open(filepath, \"r\") as f:\n",
    "            for line in f:\n",
    "                # Skip comment lines starting with %\n",
    "                if line.startswith(\"%\"):\n",
    "                    continue\n",
    "\n",
    "                # Split line into source and target nodes\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 2:  # Ensure we have at least source and target\n",
    "                    source, target = map(int, parts[:2])\n",
    "                    G.add_edge(source, target)\n",
    "\n",
    "        return G\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading network file: {str(e)}\")\n",
    "        print(f\"Make sure the file exists at: {filepath}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "connectome = nx.read_graphml(connectome_filepath)\n",
    "food_web = read_out_network_data(food_web_filepath, type = 'directed')\n",
    "zebra_web = read_out_network_data(zebra_filepath, type = 'undirected')\n",
    "\n",
    "# plot the zebra network\n",
    "# nx.draw(zebra_web, with_labels=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_largest_connected_component(G):\n",
    "    \"\"\"\n",
    "    Determines the largest connected component of a network.\n",
    "\n",
    "    Parameters:\n",
    "    G (networkx.Graph): A NetworkX graph object\n",
    "\n",
    "    Returns:\n",
    "    networkx.Graph: The largest connected component\n",
    "    \"\"\"\n",
    "    if G.is_directed():\n",
    "        largest_cc = max(nx.strongly_connected_components(G), key=len)\n",
    "    else:\n",
    "        largest_cc = max(nx.connected_components(G), key=len)\n",
    "    return G.subgraph(largest_cc).copy()\n",
    "\n",
    "\n",
    "connectome_lcc = determine_largest_connected_component(connectome)\n",
    "food_web_lcc = determine_largest_connected_component(food_web)\n",
    "zebra_web_lcc = determine_largest_connected_component(zebra_web)\n",
    "\n",
    "# print(\"\\nLargest Connected Components:\")\n",
    "# print(f\"Connectome: {connectome_lcc.number_of_nodes()} nodes, {connectome_lcc.number_of_edges()} edges\")\n",
    "# print(f\"Food Web: {food_web_lcc.number_of_nodes()} nodes, {food_web_lcc.number_of_edges()} edges\")\n",
    "# print(f\"Zebra Web: {zebra_web_lcc.number_of_nodes()} nodes, {zebra_web_lcc.number_of_edges()} edges\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Network Analysis Results:\n",
      "Connectome: C=0.9100, L=1.1000\n",
      "Food Web: C=0.3865, L=2.2597\n",
      "Zebra Web: C=0.8543, L=1.8617\n"
     ]
    }
   ],
   "source": [
    "def compute_C_and_L(G):\n",
    "    \"\"\"Computes the clustering coefficient and average shortest path length of a graph.\"\"\"\n",
    "    clustering_coeff = nx.average_clustering(G)\n",
    "\n",
    "    # Check if the graph is directed\n",
    "    if G.is_directed():\n",
    "        if nx.is_strongly_connected(\n",
    "            G\n",
    "        ):  # For directed graphs, check strong connectivity\n",
    "            path_length = nx.average_shortest_path_length(G)\n",
    "        else:\n",
    "            print(\"Graph is not strongly connected.\")\n",
    "            path_length = None  # Handle disconnected directed graphs\n",
    "    else:\n",
    "        if nx.is_connected(G):  # For undirected graphs\n",
    "            path_length = nx.average_shortest_path_length(G)\n",
    "        else:\n",
    "            print(\"Graph is not connected.\")\n",
    "            path_length = None  # Handle disconnected undirected graphs\n",
    "\n",
    "    return clustering_coeff, path_length\n",
    "\n",
    "\n",
    "connectome_C, connectome_L = compute_C_and_L(connectome_lcc)\n",
    "food_web_C, food_web_L = compute_C_and_L(food_web_lcc)\n",
    "zebra_web_C, zebra_web_L = compute_C_and_L(zebra_web_lcc)\n",
    "\n",
    "print(\"\\nNetwork Analysis Results:\")\n",
    "print(f\"Connectome: C={connectome_C:.4f}, L={connectome_L:.4f}\")\n",
    "print(f\"Food Web: C={food_web_C:.4f}, L={food_web_L:.4f}\")\n",
    "print(f\"Zebra Web: C={zebra_web_C:.4f}, L={zebra_web_L:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_configuration_model(G, num_samples=1000):\n",
    "    \"\"\"Generates a null distribution for clustering coefficient and path length using the configuration model\"\"\"\n",
    "    degrees = [d for n, d in G.degree()]\n",
    "    clustering_coeffs = []\n",
    "    path_lengths = []\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # Generate a configuration model graph\n",
    "        random_G = nx.configuration_model(degrees)\n",
    "        # Convert to simple graph (removes self-loops and parallel edges)\n",
    "        random_G = nx.Graph(random_G)\n",
    "        random_G.remove_edges_from(nx.selfloop_edges(random_G))\n",
    "\n",
    "        # Compute metrics\n",
    "        C = nx.average_clustering(random_G)\n",
    "        clustering_coeffs.append(C)\n",
    "\n",
    "        if nx.is_connected(random_G):\n",
    "            L = nx.average_shortest_path_length(random_G)\n",
    "            path_lengths.append(L)\n",
    "\n",
    "    return np.array(clustering_coeffs), np.array(path_lengths)\n",
    "\n",
    "connectome_C_null, connectome_L_null = generate_configuration_model(connectome_lcc)\n",
    "food_C_null, food_L_null = generate_configuration_model(food_web_lcc)\n",
    "zebra_C_null, zebra_L_null = generate_configuration_model(zebra_web_lcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/food_clustering.png\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/food_path.png\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/connectome_clustering.png\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/connectome_path.png\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/zebra_clustering.png\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 6.4 x 4.8 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/zebra_path.png\n"
     ]
    }
   ],
   "source": [
    "def plot_null_distribution(null_values, empirical_value, title, xlabel):\n",
    "    \"\"\"Plots the null distribution with an empirical value marker and legend.\"\"\"\n",
    "\n",
    "    # Create DataFrames for null distribution and empirical value\n",
    "    df_null = pd.DataFrame({xlabel: null_values, \"type\": \"Null Distribution\"})\n",
    "    df_empirical = pd.DataFrame({xlabel: [empirical_value], \"type\": \"Empirical Value\"})\n",
    "\n",
    "    # Combine data for plotting\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            df_null, \n",
    "            # df_empirical\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Create the plot\n",
    "    plot = (\n",
    "        ggplot(df, aes(x=xlabel))\n",
    "        + geom_histogram(\n",
    "            aes(y=\"..density..\", fill=\"type\"), bins=30, alpha=0.6, color=\"black\"\n",
    "        )  # Histogram with fill mapped to 'type'\n",
    "        + geom_density(aes(color=\"type\"), size=1, linetype = 'dashed')  # Density curve mapped to 'type'\n",
    "        + geom_vline(\n",
    "            aes(xintercept=xlabel, color=\"type\"),\n",
    "            data=df_empirical,\n",
    "            linetype=\"dashed\",\n",
    "            size=1,\n",
    "        )  # Ensure empirical value appears in legend\n",
    "        + theme_minimal()\n",
    "        + labs(title=title, x=xlabel, y=\"Density\", fill=\"Legend\", color=\"Legend\")\n",
    "        + scale_fill_manual(\n",
    "            values={\"Null Distribution\": \"skyblue\", \"Empirical Value\": \"red\"}\n",
    "        )\n",
    "        + scale_color_manual(\n",
    "            values={\"Null Distribution\": \"blue\", \"Empirical Value\": \"red\"}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return plot\n",
    "\n",
    "# Recreate plots with improved aesthetics\n",
    "plot_null_distribution(\n",
    "    food_C_null, food_web_C, \"Food Web Clustering Coefficient\", \"Clustering Coefficient\"\n",
    ").save(\"figures/food_clustering.png\")\n",
    "plot_null_distribution(food_L_null, food_web_L, \"Food Web Path Length\", \"Path Length\").save(\"figures/food_path.png\")\n",
    "\n",
    "plot_null_distribution(\n",
    "    connectome_C_null,\n",
    "    connectome_C,\n",
    "    \"Connectome Clustering Coefficient\",\n",
    "    \"Clustering Coefficient\",\n",
    ").save(\"figures/connectome_clustering.png\")\n",
    "plot_null_distribution(\n",
    "    connectome_L_null, connectome_L, \"Connectome Path Length\", \"Path Length\"\n",
    ").save(\"figures/connectome_path.png\")\n",
    "\n",
    "plot_null_distribution(\n",
    "    zebra_C_null,\n",
    "    zebra_web_C,\n",
    "    \"Zebra Web Clustering Coefficient\",\n",
    "    \"Clustering Coefficient\",\n",
    ").save(\"figures/zebra_clustering.png\")\n",
    "\n",
    "plot_null_distribution(\n",
    "    zebra_L_null, zebra_web_L, \"Zebra Web Path Length\", \"Path Length\"\n",
    ").save(\"figures/zebra_path.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. (20 pts) Null models can also be used to test hypotheses about individual nodes and their positions within the network. For example, is a high centrality value for node i actually just a function of the network’s degree structure? Here, we use this approach to revisit a classic paper in social network analysis.\n",
    "\n",
    "The Medici family was a powerful political dynasty and banking family in 15th century Florence. The classic network explanation of their power2 argues that their inﬂuence came from positioning themselves as the most central node within the network of prominent Florentine families (see the network figure below). Visit the Index of Complex Networks and obtain a copy of the Medici network data file, under the “Padgett Florentine families” ICON entry. Conduct the following tests of the Medici structural importance hypothesis. Define the harmonic centrality of a node as\n",
    "\n",
    "$$\n",
    "C_{i} = \\frac{1}{n-1}\\sum_{j=1 ; j \\neq i}^{n}\\frac{1}{\\ell_{ij}}    \n",
    "$$\n",
    "\n",
    "where $\\ell_{ij}$ is the length of the shortest path from node $i$ to node $j$; if there is no such path, i.e., because $i$ and $j$ are in different components, then we define $\\ell_{ij} = \\inf$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_medici_network(filepath):\n",
    "    G = nx.Graph()\n",
    "    family_names = {}\n",
    "\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            match = re.match(r\"(\\d+)\\s([^,]+),\\s(\\d+)\\s(\\d+)\\s\\[(.*)\\]\", line.strip())\n",
    "            if match:\n",
    "                family_id = int(match.group(1))\n",
    "                family_name = match.group(2)\n",
    "                num_connections = int(match.group(3))\n",
    "                connections = match.group(5).strip()\n",
    "\n",
    "                family_names[family_id] = family_name\n",
    "\n",
    "                # Add node to the graph even if it has no connections\n",
    "                G.add_node(family_id)\n",
    "\n",
    "                if num_connections > 0 and connections:\n",
    "                    edges = []\n",
    "                    for conn in connections.split(\")\"):\n",
    "                        if conn.strip():\n",
    "                            pair = conn.strip(\" (\").split(\", \")\n",
    "                            connected_family, weight = int(pair[0]), int(pair[1])\n",
    "                            edges.append((family_id, connected_family, weight))\n",
    "\n",
    "                    for edge in edges:\n",
    "                        G.add_edge(edge[0], edge[1], weight=edge[2])\n",
    "\n",
    "    return G, family_names\n",
    "\n",
    "\n",
    "# Path to your Medici network data file\n",
    "medici_filepath = \"files/Medici network/medici_network.txt\"\n",
    "medici_network, family_names = read_medici_network(medici_filepath)\n",
    "\n",
    "# # # Visualizing the network\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# pos = nx.spring_layout(medici_network, seed=42)  # Layout the nodes\n",
    "\n",
    "# # # Draw the nodes, edges, and labels\n",
    "# nx.draw(\n",
    "#     medici_network,\n",
    "#     pos,\n",
    "#     with_labels=True,\n",
    "#     node_size=3000,\n",
    "#     node_color=\"skyblue\",\n",
    "#     font_size=10,\n",
    "#     font_weight=\"bold\",\n",
    "#     edge_color=\"gray\",\n",
    "# )\n",
    "# plt.title(\"Medici Family Network\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Calculate and report the harmonic centrality of each node in the Medici network, and\n",
    "comment on where in the corresponding ranking the Medici family appears. Then discuss\n",
    "the degree to which your findings agree with the network explanation of the Medici’s\n",
    "power, and what the scores say about how important is second most important family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Node  Harmonic Centrality   Family Name\n",
      "8      8             0.633333        Medici\n",
      "6      6             0.538889      Guadagni\n",
      "12    12             0.533333       Ridolfi\n",
      "1      1             0.522222       Albizzi\n",
      "14    14             0.522222       Strozzi\n",
      "15    15             0.522222    Tornabuoni\n",
      "3      3             0.480000      Bischeri\n",
      "2      2             0.472222     Barbadori\n",
      "4      4             0.461111    Castellani\n",
      "10    10             0.452222       Peruzzi\n",
      "13    13             0.438889      Salviati\n",
      "0      0             0.394444    Acciaiuoli\n",
      "7      7             0.357778  Lamberteschi\n",
      "5      5             0.355556        Ginori\n",
      "9      9             0.317778         Pazzi\n",
      "11    11             0.000000         Pucci\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 12 x 6 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/harmonic_centrality.png\n"
     ]
    }
   ],
   "source": [
    "def calculate_harmonic_centrality(G):\n",
    "    \"\"\"\n",
    "    Calculates the harmonic centrality of nodes in a graph.\n",
    "\n",
    "    Parameters:\n",
    "    G (networkx.Graph): A NetworkX graph object\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of harmonic centrality values for each node\n",
    "    \"\"\"\n",
    "    # Compute harmonic centrality using NetworkX's built-in function\n",
    "    harmonic_centrality = nx.harmonic_centrality(G)\n",
    "\n",
    "    # Print results for debugging\n",
    "    # print(\"Harmonic Centrality:\", harmonic_centrality)\n",
    "\n",
    "    for node in G.nodes():\n",
    "        # Normalize the harmonic centrality by n-1\n",
    "        harmonic_centrality[node] = (1 / (len(G.nodes()) - 1)) * harmonic_centrality[node]\n",
    "\n",
    "    return harmonic_centrality\n",
    "\n",
    "\n",
    "medici_harmonic_centrality = calculate_harmonic_centrality(medici_network)\n",
    "\n",
    "# can we make a figure for this?\n",
    "# Create a DataFrame for plotting\n",
    "df_harmonic = pd.DataFrame(\n",
    "    {\n",
    "        \"Node\": list(medici_harmonic_centrality.keys()),\n",
    "        \"Harmonic Centrality\": list(medici_harmonic_centrality.values()),\n",
    "    }\n",
    ")\n",
    "\n",
    "# transform the harmonic centrality values to 1/(n-1) where n is the number of nodes\n",
    "# df_harmonic[\"Harmonic Centrality\"] = 1 / (len(df_harmonic[\"Harmonic Centrality\"]) - 1) * df_harmonic[\"Harmonic Centrality\"]\n",
    "\n",
    "# Add family names\n",
    "df_harmonic[\"Family Name\"] = df_harmonic[\"Node\"].map(family_names)\n",
    "\n",
    "# Sort by harmonic centrality\n",
    "df_harmonic = df_harmonic.sort_values(\"Harmonic Centrality\", ascending=False)\n",
    "\n",
    "# Print sorted ranking\n",
    "print(df_harmonic)\n",
    "\n",
    "# Create the plot\n",
    "plot_harmonic = (\n",
    "    ggplot(df_harmonic, aes(x=\"Family Name\", y=\"Harmonic Centrality\", fill=\"factor(Node)\"))\n",
    "    + geom_bar(stat=\"identity\", color=\"black\")  # Keep border for better visibility\n",
    "    + theme_minimal()\n",
    "    + labs(\n",
    "        title=\"Harmonic Centrality of Medici Family Network\",\n",
    "        x=\"Node\",\n",
    "        y=\"Harmonic Centrality\",\n",
    "    )\n",
    "    # + scale_fill_viridis_d()\n",
    "    + theme(legend_position=\"none\", axis_text_x=element_text(angle=45, hjust=1), figure_size=(12, 6))\n",
    ")\n",
    "\n",
    "plot_harmonic.save(\"figures/harmonic_centrality.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Design and carry out a numerical experiment to answer the question: to what degree can each family’s structural importance be explained as purely a function of the network’s degree sequence $\\vec{k}$? Use these results to assess the network explanation of the Medici’s power, and explain how your results answer that question. Comment on which other families are more (or less) important than we expect under the null model.\n",
    "\n",
    "Hint: If a family’s centrality score is ‘typical’ in the null model, then we conclude that its centrality can be explained entirely by the network’s degree sequence; if it not typical, then we conclude that other factors (beyond degrees) are needed to explain its centrality, e.g., it could be more central than we expect, or less!\n",
    "\n",
    "Hint: As above, 1000 random graphs should give you a good null distribution, and it\n",
    "should be sufficient to apply r = 20m double-edge swaps to produce one such graph.\n",
    "Because you need to look at all the families, a good visualization would arrange the node indices on the x-axis and plot for each the corresponding distribution of $(C_{i}^{null})_{j} - C_{i}^{data}$, where $j$ indexes the random graphs. The degree to which each distribution spans $y = 0$ is then informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 12 x 6 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/centrality_differences.png\n"
     ]
    }
   ],
   "source": [
    "# Load original Medici network\n",
    "G = medici_network\n",
    "\n",
    "# Compute harmonic centrality in original network\n",
    "data_harmonic_centrality = calculate_harmonic_centrality(G)\n",
    "\n",
    "# Generate null model distributions\n",
    "m = G.number_of_edges()\n",
    "num_samples = 1000\n",
    "centrality_differences = {node: [] for node in G.nodes()}\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Generate null model while preserving degree sequence\n",
    "    G_null = G.copy()\n",
    "    G_null = nx.double_edge_swap(G_null, nswap=20 * m, max_tries=1000)\n",
    "\n",
    "    # Calculate centrality for null model\n",
    "    null_centrality = calculate_harmonic_centrality(G_null)\n",
    "\n",
    "    # Store differences between null model and original data\n",
    "    for node in G.nodes():\n",
    "        diff = null_centrality[node] - data_harmonic_centrality[node]\n",
    "        centrality_differences[node].append(diff)\n",
    "\n",
    "# Prepare data for visualization\n",
    "plot_data = []\n",
    "for node in G.nodes():\n",
    "    diffs = centrality_differences[node]\n",
    "    family = family_names[node]\n",
    "    plot_data.extend([(family, d) for d in diffs])\n",
    "\n",
    "df_plot = pd.DataFrame(plot_data, columns=[\"Family\", \"Centrality Difference\"])\n",
    "\n",
    "# Create violin plot of differences\n",
    "violin_plot = (\n",
    "    ggplot(df_plot, aes(x=\"Family\", y=\"Centrality Difference\"))\n",
    "    + geom_violin(aes(fill=\"Family\"), alpha=0.5)\n",
    "    + geom_point(aes(color=\"Family\"), position=position_jitter(width=0.01), alpha=0.3, size = 1)\n",
    "    + geom_hline(yintercept=0, linetype=\"dashed\", color=\"red\")\n",
    "    + labs(\n",
    "        title=\"Distribution of Centrality Differences (Null Model - Original)\",\n",
    "        x=\"Family Name\",\n",
    "        y=\"Difference in Harmonic Centrality\",\n",
    "    )\n",
    "    + theme_minimal()\n",
    "    + theme(axis_text_x=element_text(rotation=45, hjust=1), figure_size=(12, 6), legend_position=\"none\")\n",
    ")\n",
    "\n",
    "violin_plot.save(\"figures/centrality_differences.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) (10 pts extra credit) Repeat the above experiment but change the null model to one that uses “the wrong” graph space. Specifically, use the stub-matching algorithm to construct stub-labeled loopy multigraphs, which you then “simplify” by removing self-loops and collapsing multiedges. Make the same plot as before, and discuss how your results here differ (if at all) from when you use the correct null model (one that matches the data’s graph space), and what conclusions would change (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 12 x 6 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/centrality_differences_stub_matching.png\n"
     ]
    }
   ],
   "source": [
    "def generate_wrong_null_model(G):\n",
    "    \"\"\"\n",
    "    Generate a null model using configuration model that creates a multigraph,\n",
    "    then simplify it by removing self-loops and collapsing multiple edges.\n",
    "    \"\"\"\n",
    "    # Get degree sequence from original graph\n",
    "    degree_sequence = [d for _, d in G.degree()]\n",
    "\n",
    "    # Generate multigraph using configuration model\n",
    "    G_null = nx.configuration_model(degree_sequence)\n",
    "\n",
    "    # Convert to simple graph (this step collapses multiple edges and removes self-loops)\n",
    "    G_null = nx.Graph(G_null)\n",
    "\n",
    "    return G_null\n",
    "\n",
    "\n",
    "# Load original Medici network\n",
    "G = medici_network\n",
    "degree_sequence = [d for _, d in G.degree()]\n",
    "\n",
    "# Compute harmonic centrality in original network\n",
    "data_harmonic_centrality = calculate_harmonic_centrality(G)\n",
    "\n",
    "# Generate null model distributions\n",
    "num_samples = 1000\n",
    "centrality_differences = {node: [] for node in G.nodes()}\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Generate null model using configuration model and simplification\n",
    "    G_null = generate_wrong_null_model(G)\n",
    "\n",
    "    # Calculate centrality for null model\n",
    "    null_centrality = calculate_harmonic_centrality(G_null)\n",
    "\n",
    "    # Store differences between null model and original data\n",
    "    for node in G.nodes():\n",
    "        # Handle case where node might be disconnected in null model\n",
    "        null_value = null_centrality.get(node, 0)\n",
    "        diff = null_value - data_harmonic_centrality[node]\n",
    "        centrality_differences[node].append(diff)\n",
    "\n",
    "\n",
    "# Prepare data for visualization\n",
    "plot_data = []\n",
    "for node in G.nodes():\n",
    "    diffs = centrality_differences[node]\n",
    "    family = family_names[node]\n",
    "    plot_data.extend([(family, d) for d in diffs])\n",
    "\n",
    "df_plot = pd.DataFrame(plot_data, columns=[\"Family\", \"Centrality Difference\"])\n",
    "\n",
    "# Create violin plot of differences\n",
    "plot = (\n",
    "    ggplot(df_plot, aes(x=\"Family\", y=\"Centrality Difference\"))\n",
    "    + geom_violin(aes(fill=\"Family\"), alpha=0.5)\n",
    "    + geom_point(aes(color=\"Family\"), position=position_jitter(width=0.01), alpha=0.3, size = 1)\n",
    "    + geom_hline(yintercept=0, linetype=\"dashed\", color=\"red\")\n",
    "    + labs(\n",
    "        title=\"Distribution of Centrality Differences (Stub-Matching Null - Original)\",\n",
    "        x=\"Family Name\",\n",
    "        y=\"Difference in Harmonic Centrality\",\n",
    "    )\n",
    "    + theme_minimal()\n",
    "    + theme(axis_text_x=element_text(rotation=45, hjust=1), figure_size=(12, 6), legend_position=\"none\")\n",
    ")\n",
    "\n",
    "plot.save(\"figures/centrality_differences_stub_matching.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (20 pts extra credit) In the Watts-Strogatz model, the ﬁrst few rewired edges play an outsized role in collapsing the path-length distribution, as they act like highways for shortest paths to cross the center of the ring. But as we rewire more edges, each highway carries progressively less traﬃc because we’re creating many alternate avenues and the shortest-path traﬃc gets distributed more evenly until, when $p = 1$, every edge should carry roughly an equal fraction\n",
    "of all shortest paths.\n",
    "\n",
    "Design and carry out a numerical experiment that shows how the distribution of *betweenness centrality* values relaxes across the network as we rewire progressively more edges. Let $r$ count the number of edges rewired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:615: PlotnineWarning: Saving 12 x 6 in image.\n",
      "/opt/anaconda3/envs/networks/lib/python3.12/site-packages/plotnine/ggplot.py:616: PlotnineWarning: Filename: figures/betweenness_distribution.png\n"
     ]
    }
   ],
   "source": [
    "def create_ws_with_rewiring_count(n, k, r):\n",
    "    \"\"\"\n",
    "    Create a Watts-Strogatz graph with exactly r edges rewired.\n",
    "\n",
    "    Parameters:\n",
    "    n : int - Number of nodes\n",
    "    k : int - Each node is connected to k nearest neighbors\n",
    "    r : int - Number of edges to rewire\n",
    "\n",
    "    Returns:\n",
    "    G : networkx.Graph - The generated graph\n",
    "    actual_rewired : int - Actual number of edges rewired\n",
    "    \"\"\"\n",
    "    G = nx.watts_strogatz_graph(n, k, 0)\n",
    "    edges = list(G.edges())\n",
    "    nodes = list(G.nodes())\n",
    "\n",
    "    rewired = 0\n",
    "    attempts = 0\n",
    "    max_attempts = r * 10\n",
    "\n",
    "    # Keep track of rewired edges to prevent rewiring the same edge twice\n",
    "    rewired_edges = set()\n",
    "\n",
    "    while rewired < r and attempts < max_attempts:\n",
    "        if not edges:\n",
    "            break\n",
    "\n",
    "        # Choose a random edge that hasn't been rewired yet\n",
    "        available_edges = [(u, v) for u, v in edges if (u, v) not in rewired_edges]\n",
    "        if not available_edges:\n",
    "            break\n",
    "\n",
    "        u, v = available_edges[np.random.randint(len(available_edges))]\n",
    "\n",
    "        # Choose new target node, excluding current neighbors and self\n",
    "        possible_targets = [\n",
    "            w for w in nodes if w != u and w != v and not G.has_edge(u, w)\n",
    "        ]\n",
    "\n",
    "        if possible_targets:\n",
    "            w = np.random.choice(possible_targets)\n",
    "            G.remove_edge(u, v)\n",
    "            G.add_edge(u, w)\n",
    "            rewired += 1\n",
    "            rewired_edges.add((u, v))\n",
    "            rewired_edges.add((v, u))  # Add both directions\n",
    "\n",
    "        attempts += 1\n",
    "\n",
    "    return G, rewired\n",
    "\n",
    "\n",
    "def analyze_betweenness_distribution(n=100, k=4, num_points=10, num_iterations=5):\n",
    "    \"\"\"\n",
    "    Analyze betweenness centrality distribution with multiple iterations per rewiring value.\n",
    "\n",
    "    Parameters:\n",
    "    n : int - Number of nodes\n",
    "    k : int - Each node is connected to k nearest neighbors\n",
    "    num_points : int - Number of different rewiring values to test\n",
    "    num_iterations : int - Number of networks to generate per rewiring value\n",
    "    \"\"\"\n",
    "    max_rewiring = (n * k) // 4\n",
    "    r_values = np.unique(np.logspace(0, np.log10(max_rewiring), num_points).astype(int))\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for r in r_values:\n",
    "        for iteration in range(num_iterations):\n",
    "            G, actual_rewired = create_ws_with_rewiring_count(n, k, r)\n",
    "            bc = nx.betweenness_centrality(G)\n",
    "\n",
    "            # Calculate additional network metrics\n",
    "            avg_path_length = nx.average_shortest_path_length(G)\n",
    "            clustering_coef = nx.average_clustering(G)\n",
    "\n",
    "            all_data.extend(\n",
    "                [\n",
    "                    {\n",
    "                        \"target_rewiring\": r,\n",
    "                        \"actual_rewiring\": actual_rewired,\n",
    "                        \"betweenness\": bc_value,\n",
    "                        \"iteration\": iteration,\n",
    "                        \"avg_path_length\": avg_path_length,\n",
    "                        \"clustering_coef\": clustering_coef,\n",
    "                    }\n",
    "                    for bc_value in bc.values()\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "# Run analysis with multiple iterations\n",
    "n, k = 100, 4\n",
    "df = analyze_betweenness_distribution(n, k, num_iterations=5)\n",
    "\n",
    "# Create an enhanced plot\n",
    "plot = (\n",
    "    ggplot(\n",
    "        df,\n",
    "        aes(\n",
    "            x=\"factor(target_rewiring)\", y=\"betweenness\", fill=\"factor(actual_rewiring)\"\n",
    "        ),\n",
    "    )\n",
    "    + geom_violin(alpha=0.5)\n",
    "    + geom_point(aes(color=\"factor(actual_rewiring)\"), alpha=0.5, size=0.5)\n",
    "    + theme_minimal()\n",
    "    + labs(\n",
    "        title=\"Betweenness Centrality Distribution in Watts-Strogatz Networks\",\n",
    "        x=\"Number of Edges Rewired (log scale)\",\n",
    "        y=\"Betweenness Centrality\",\n",
    "        fill=\"Actual Rewiring\",\n",
    "    )\n",
    "    + theme(\n",
    "        plot_title=element_text(size=12),\n",
    "        plot_subtitle=element_text(size=10),\n",
    "        axis_text_x=element_text(angle=45, hjust=1),\n",
    "        figure_size=(12, 6),\n",
    "        legend_position='none'\n",
    "    )\n",
    ")\n",
    "\n",
    "plot.save(\"figures/betweenness_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "networks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
